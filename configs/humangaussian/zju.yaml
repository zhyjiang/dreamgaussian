### Output
outdir: logs
mesh_format: obj
save_path: checkpoints
save_name: temp_ZJU_test
save_interval: 25
eval_interval: 1




crop_image: False
dino:
  image_embed: True
  name: ViT-S
  path: dino_vits16

vis_path: temp_ZJU_test

vis_ply_path: temp_ZJU_test

vis_second_view: temp_second_view_ZJU_test





vis_depth_path: temp_depth_ZJU_test

vis_eval: temp_vis_eval_ZJU_test

vis_eval_depth_path: temp_depth_eval_ZJU_test
dataset_type:  ZJU
dataset:
  name: ZJU  #HuMMan
  # path: [./data/ZJUMOCAP/CoreView_313, ./data/ZJUMOCAP/CoreView_314, ./data/ZJUMOCAP/CoreView_315, ./data/ZJUMOCAP/CoreView_316, ./data/ZJUMOCAP/CoreView_317, ./data/ZJUMOCAP/CoreView_318, ./data/ZJUMOCAP/CoreView_319, ./data/ZJUMOCAP/CoreView_320, ./data/ZJUMOCAP/CoreView_321, ./data/ZJUMOCAP/CoreView_322, ./data/ZJUMOCAP/CoreView_323, ./data/ZJUMOCAP/CoreView_324, ./data/ZJUMOCAP/CoreView_325, ./data/ZJUMOCAP/CoreView_326, ./data/ZJUMOCAP/CoreView_327, ./data/ZJUMOCAP/CoreView_328, ./data/ZJUMOCAP/CoreView_329, ./data/ZJUMOCAP/CoreView_330, ./data/ZJUMOCAP/CoreView_331, ./data/ZJUMOCAP/CoreView_332, ./data/ZJUMOCAP/CoreView_333, ./data/ZJUMOCAP/CoreView_334, ./data/ZJUMOCAP/CoreView_335, ./data/ZJUMOCAP/CoreView_336, ./data/ZJUMOCAP/CoreView_337, ./data/ZJUMOCAP/CoreView_338, ./data/ZJUMOCAP/CoreView_339, ./data/ZJUMOCAP/CoreView_340, ./data/ZJUMOCAP/CoreView_341, ./data/ZJUMOCAP/CoreView_342, ./data/ZJUMOCAP/CoreView_343, ./data/ZJUMOCAP/CoreView_344, ./data/ZJUMOCAP/CoreView_345, ./data/ZJUMOCAP/CoreView_346, ./data/ZJUMOCAP/CoreView_347, ./data/ZJUMOCAP/CoreView_348, ./data/ZJUMOCAP/CoreView_349, ./data/ZJUMOCAP/CoreView_350, ./data/ZJUMOCAP/CoreView_351, ./data/ZJUMOCAP/CoreView_352, ./data/ZJUMOCAP/CoreView_353, ./data/ZJUMOCAP/CoreView_354, ./data/ZJUMOCAP/Core
  # camera_list: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\
  root: ./data/ZJUMOCAP/ 
  # path: [313]
  path: [394]
  test_path: [390,393]
  camera_list: [1,4,7,9]
  num_workers: 0
  smpl_coord: True
  sample_rate: 2
  eval_sample_rate: 80
  img_emb_dim:  4096
  H: 1024
  W: 1024
  pose_num: 24


dataset2:
  name: HuMMan
  smpl_path : SMPL/ROMP_SMPL/SMPL_NEUTRAL.pth
  root: /mnt/nvme/Dataset/HuMMan/
  split: train
  multi_person: True
  num_workers: 8
  num_instances: 1
  img_emb_dim:  196 #8040
  H: 1080
  W: 1920
  pose_num: 23



### Training
# guidance loss weights (0 to disable)
canonical: False
param_input: True
camera_param : False
trans_decoder: True
cross_attn: True
lambda_sd: 1
mvdream: False
lambda_zero123: 0
full_token: True
reshape: True
dino_update : True
# training batch size per iter
batch_size: 1
# training iterations for stage 1
iters: 1000

multi_view: 1
# whether to linearly anneal timestep
anneal_timestep: True
# training iterations for stage 2
iters_refine: 50
# training camera radius
radius: 2.5
# training camera fovy
fovy: 49.1
# checkpoint to load for stage 1 (should be a ply file)
load:
# whether allow geom training in stage 2
train_geo: False
# prob to invert background color during training (0 = always black, 1 = always white)
invert_bg_prob: 0.5

ssim_weight: 0.2

scale_factor: 0.001 #0.001

smpl_reg_scale:  0.01 # 0.01

IOU_init_weight : 0.1

IOU_weight: 0.005

upsample: 4 # 1
loss:  ssim_l2 # [l1 l2 ssim_l2 ssim_l1] #silou loss needs to be added in the next version
reg_loss: l2 # [l1 l2 or None]



lr: 0.001 #0.001
base_lr: 0.0001 #0.0001
warmup: 10 #10

### GUI
gui: False
force_cuda_rast: False
# GUI resolution
# H: 1024

# W: 1024
near: 0.1
far: 100

### Gaussian splatting
num_pts: 5000
sh_degree: 0
position_lr_init: 0.001
position_lr_final: 0.00002
position_lr_delay_mult: 0.02
position_lr_max_steps: 300
feature_lr: 0.01
opacity_lr: 0.05
scaling_lr: 0.005
rotation_lr: 0.005
percent_dense: 0.01
density_start_iter: 0
density_end_iter: 3000
densification_interval: 50
opacity_reset_interval: 700
densify_grad_threshold: 0.01

### Textured Mesh
geom_lr: 0.0001
texture_lr: 0.2